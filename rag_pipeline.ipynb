{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T23:35:17.012092Z",
     "start_time": "2025-09-13T23:35:16.528527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "# Загрузка текста статьи\n",
    "url = \"https://blog.dzencode.com/ru/illyuziya-kachestva-vash-sayt-idealen-pozdravlyaem-vy-tolko-chto-sozhgli-byudzhet/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "article_text = soup.get_text(separator='\\n')\n",
    "\n",
    "# Сохранение текста\n",
    "with open('artifacts/article.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(article_text)\n",
    "\n",
    "# Метаданные\n",
    "metadata = {\n",
    "    \"url\": url,\n",
    "    \"language\": \"ru\",\n",
    "    \"date\": \"unknown\",  # Дата не указана, можно уточнить позже\n",
    "    \"topic\": \"Иллюзия качества в веб-дизайне\",\n",
    "    \"project\": \"RAG_Pipeline_Test\",\n",
    "    \"lang\": \"ru\"\n",
    "}\n",
    "with open('artifacts/metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)"
   ],
   "id": "cd7aaf2855bf1a94",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T23:35:17.030676Z",
     "start_time": "2025-09-13T23:35:17.018212Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Чтение исходного текста\n",
    "with open('artifacts/article.txt', 'r', encoding='utf-8') as f:\n",
    "    article_text = f.read()\n",
    "\n",
    "# Предобработка: удаление HTML-тегов и лишних символов\n",
    "cleaned_text = re.sub(r'<.*?>', '', article_text)  # Удаление HTML-тегов\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Замена множества пробелов на один\n",
    "cleaned_lines = cleaned_text.splitlines()  # Разбиение по любым разрывам строк\n",
    "cleaned_text = '\\n'.join(line.strip() for line in cleaned_lines if line.strip())  # Фильтр пустых строк\n",
    "\n",
    "# Сохранение чистого текста\n",
    "with open('artifacts/cleaned_article.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaned_text)"
   ],
   "id": "eb45dfd05873e40d",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T23:35:17.063246Z",
     "start_time": "2025-09-13T23:35:17.046497Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Чтение очищенного текста\n",
    "with open('artifacts/cleaned_article.txt', 'r', encoding='utf-8') as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# Разбиение на чанки\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "# Подготовка данных для JSONL с ID и метаданными\n",
    "data = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    entry = {\n",
    "        \"id\": i,\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"url\": \"https://blog.dzencode.com/ru/illyuziya-kachestva-vash-sayt-idealen-pozdravlyaem-vy-tolko-chto-sozhgli-byudzhet/\",\n",
    "            \"language\": \"ru\",\n",
    "            \"date\": \"unknown\",\n",
    "            \"topic\": \"Иллюзия качества в веб-дизайне\",\n",
    "            \"project\": \"RAG_Pipeline_Test\"\n",
    "        }\n",
    "    }\n",
    "    data.append(entry)\n",
    "\n",
    "# Сохранение в JSONL\n",
    "with open('artifacts/rag_article.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for entry in data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')"
   ],
   "id": "bb5f229f475b136c",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T23:35:24.292680Z",
     "start_time": "2025-09-13T23:35:17.077729Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "import json\n",
    "import pickle\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Чтение чанков из JSONL\n",
    "chunks = []\n",
    "try:\n",
    "    with open('artifacts/rag_article.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Файл 'artifacts/rag_article.jsonl' не найден.\")\n",
    "    raise\n",
    "\n",
    "# Генерация эмбеддингов\n",
    "texts = [chunk['text'] if chunk['text'] else \" \" for chunk in chunks]\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "# Подключение к Qdrant\n",
    "try:\n",
    "    client = QdrantClient(host='localhost', port=6334)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка подключения к Qdrant: {e}\")\n",
    "    raise\n",
    "\n",
    "# Очистка и создание коллекции\n",
    "collection_name = \"rag_article_collection\"\n",
    "if client.collection_exists(collection_name):\n",
    "    client.delete_collection(collection_name)\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=len(vectors[0]),\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Загрузка данных в Qdrant\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=chunk['id'],\n",
    "        vector=vector,\n",
    "        payload=chunk['metadata']\n",
    "    )\n",
    "    for chunk, vector in zip(chunks, vectors)\n",
    "]\n",
    "client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Сохранение эмбеддингов\n",
    "with open('artifacts/embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(vectors, f)"
   ],
   "id": "f96ac98ac3ebe6ea",
   "outputs": [],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T23:35:26.497613Z",
     "start_time": "2025-09-13T23:35:24.307596Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=\"ru_RU\", use_fast=False)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "    print(f\"Модель {MODEL_NAME} успешно загружена\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки модели {MODEL_NAME}: {e}\")\n",
    "    raise"
   ],
   "id": "11e5587e2e57e3f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель facebook/mbart-large-50-many-to-many-mmt успешно загружена\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-13T23:42:47.756345Z",
     "start_time": "2025-09-13T23:42:33.908618Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import json\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Подключение к Qdrant\n",
    "client = QdrantClient(host='localhost', port=6334)\n",
    "collection_name = \"rag_article_collection\"\n",
    "\n",
    "# Загрузка чанков из JSONL\n",
    "chunks = []\n",
    "with open('artifacts/rag_article.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))\n",
    "\n",
    "# Словарь для доступа к тексту по id\n",
    "chunk_dict = {chunk['id']: chunk['text'] for chunk in chunks}\n",
    "\n",
    "\n",
    "# Поиск релевантных чанков\n",
    "def search_chunks(query, top_k=3, min_score=0.4):\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "    search_result = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    ).points\n",
    "    matched_chunks = [\n",
    "        chunk_dict[hit.id] for hit in search_result\n",
    "        if hit.id in chunk_dict and hit.score >= min_score\n",
    "    ]\n",
    "    return matched_chunks\n",
    "\n",
    "\n",
    "# Генерация ответа\n",
    "def generate_response(query, chunks):\n",
    "    if not chunks:\n",
    "        return \"Не удалось найти релевантный контекст.\"\n",
    "    context = chunks[0]  # Используем самый релевантный чанк\n",
    "    tokenized_context = tokenizer(context, truncation=True, max_length=150, return_tensors=\"pt\")\n",
    "    truncated_context = tokenizer.decode(tokenized_context[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    prompt = f\"\"\"Ответь на русском языке кратко, используя контекст.\n",
    "\n",
    "Вопрос: {query}\n",
    "Контекст: {truncated_context}\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=False,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[\"ru_RU\"]\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    return response\n",
    "\n",
    "\n",
    "# Проверка коллекции\n",
    "collection_info = client.get_collection(collection_name=collection_name)\n",
    "if collection_info.points_count == 0 or collection_info.points_count != len(chunk_dict):\n",
    "    raise SystemExit\n",
    "\n",
    "# Запрос\n",
    "query = \"Что автор имеет в виду под 'иллюзией качества'?\"\n",
    "\n",
    "# Основной поиск и генерация\n",
    "relevant_chunks = search_chunks(query, top_k=3, min_score=0.4)\n",
    "answer = generate_response(query, relevant_chunks)\n",
    "\n",
    "# Сохранение результата\n",
    "result = {\"query\": query, \"answer\": answer, \"relevant_chunks\": relevant_chunks}\n",
    "with open('artifacts/rag_result.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Вывод\n",
    "print(f\"\\nВопрос: {query}\")\n",
    "print(f\"Ответ: {answer}\")\n",
    "print(\"Релевантные чанки:\")\n",
    "for i, chunk in enumerate(relevant_chunks, 1):\n",
    "    print(f\"Чанк {i}: {chunk[:100]}...\" if chunk else f\"Чанк {i}: Пусто\")"
   ],
   "id": "deca4b09975ae2e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Вопрос: Что автор подразумевает под пустотой в цифровом продукте?\n",
      "Ответ: Вопрос: Что автор подразумевает под пустотой в цифровом продукте? Контекст: рассекаем “Качество” Иллюзия Качества — это когда вы платите за лоск, а получаете пустоту Качество цифрового продукта — как луковица. Наруже — красивые, гладкие слои:глянец, стиль, “вау”. Внутри — ядро: логика, смысл, результат. Иллюзия Качества — это когда вы купите шелуху, перепутав ее с сердцевиной.\n",
      "Релевантные чанки:\n",
      "Чанк 1: рассекаем “Качество” Иллюзия Качества — это когда вы платите за лоск, а получаете пустоту Качество ц...\n",
      "Чанк 2: №2: “Лендинг-аттракцион” Диагноз: Смерть от параллакса. История болезни: Молодой, амбициозный старта...\n",
      "Чанк 3: с мобильных устройств? ЧТО ДАЛЬШЕ? Легко ли поддерживать и развивать этот продукт? Или каждая новая ...\n"
     ]
    }
   ],
   "execution_count": 62
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7435cbd788c6e4ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4495d129236a61ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
