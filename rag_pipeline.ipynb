{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:05:27.753523Z",
     "start_time": "2025-09-14T00:05:27.207167Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "# Загрузка текста статьи\n",
    "url = \"https://blog.dzencode.com/ru/illyuziya-kachestva-vash-sayt-idealen-pozdravlyaem-vy-tolko-chto-sozhgli-byudzhet/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "article_text = soup.get_text(separator='\\n')\n",
    "\n",
    "# Сохранение текста\n",
    "with open('artifacts/article.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(article_text)\n",
    "\n",
    "# Метаданные\n",
    "metadata = {\n",
    "    \"url\": url,\n",
    "    \"language\": \"ru\",\n",
    "    \"date\": \"unknown\",  # Дата не указана, можно уточнить позже\n",
    "    \"topic\": \"Иллюзия качества в веб-дизайне\",\n",
    "    \"project\": \"RAG_Pipeline_Test\",\n",
    "    \"lang\": \"ru\"\n",
    "}\n",
    "with open('artifacts/metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)"
   ],
   "id": "cd7aaf2855bf1a94",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:05:27.793079Z",
     "start_time": "2025-09-14T00:05:27.779924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Чтение исходного текста\n",
    "with open('artifacts/article.txt', 'r', encoding='utf-8') as f:\n",
    "    article_text = f.read()\n",
    "\n",
    "# Предобработка: удаление HTML-тегов и лишних символов\n",
    "cleaned_text = re.sub(r'<.*?>', '', article_text)  # Удаление HTML-тегов\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Замена множества пробелов на один\n",
    "cleaned_lines = cleaned_text.splitlines()  # Разбиение по любым разрывам строк\n",
    "cleaned_text = '\\n'.join(line.strip() for line in cleaned_lines if line.strip())  # Фильтр пустых строк\n",
    "\n",
    "# Сохранение чистого текста\n",
    "with open('artifacts/cleaned_article.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaned_text)"
   ],
   "id": "eb45dfd05873e40d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:05:29.261436Z",
     "start_time": "2025-09-14T00:05:27.956476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Чтение очищенного текста\n",
    "with open('artifacts/cleaned_article.txt', 'r', encoding='utf-8') as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# Разбиение на чанки\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "# Подготовка данных для JSONL с ID и метаданными\n",
    "data = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    entry = {\n",
    "        \"id\": i,\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"url\": \"https://blog.dzencode.com/ru/illyuziya-kachestva-vash-sayt-idealen-pozdravlyaem-vy-tolko-chto-sozhgli-byudzhet/\",\n",
    "            \"language\": \"ru\",\n",
    "            \"date\": \"unknown\",\n",
    "            \"topic\": \"Иллюзия качества в веб-дизайне\",\n",
    "            \"project\": \"RAG_Pipeline_Test\"\n",
    "        }\n",
    "    }\n",
    "    data.append(entry)\n",
    "\n",
    "# Сохранение в JSONL\n",
    "with open('artifacts/rag_article.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for entry in data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')"
   ],
   "id": "bb5f229f475b136c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:06:28.076008Z",
     "start_time": "2025-09-14T00:05:29.280161Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "import json\n",
    "import pickle\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Чтение чанков из JSONL\n",
    "chunks = []\n",
    "try:\n",
    "    with open('artifacts/rag_article.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Файл 'artifacts/rag_article.jsonl' не найден.\")\n",
    "    raise\n",
    "\n",
    "# Генерация эмбеддингов\n",
    "texts = [chunk['text'] if chunk['text'] else \" \" for chunk in chunks]\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "# Подключение к Qdrant\n",
    "try:\n",
    "    client = QdrantClient(host='localhost', port=6334)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка подключения к Qdrant: {e}\")\n",
    "    raise\n",
    "\n",
    "# Очистка и создание коллекции\n",
    "collection_name = \"rag_article_collection\"\n",
    "if client.collection_exists(collection_name):\n",
    "    client.delete_collection(collection_name)\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=len(vectors[0]),\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Загрузка данных в Qdrant\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=chunk['id'],\n",
    "        vector=vector,\n",
    "        payload=chunk['metadata']\n",
    "    )\n",
    "    for chunk, vector in zip(chunks, vectors)\n",
    "]\n",
    "client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Сохранение эмбеддингов\n",
    "with open('artifacts/embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(vectors, f)"
   ],
   "id": "f96ac98ac3ebe6ea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balnc3r\\AppData\\Local\\Temp\\ipykernel_9496\\781482672.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4b2471671a446a09fd7eee93001e084"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Projects\\RAG_Test\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\balnc3r\\.cache\\huggingface\\hub\\models--sentence-transformers--paraphrase-multilingual-MiniLM-L12-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2acb30b9431f4b71ac56752dc4651b1e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "55f44862bfe2415f838ba505bd45b100"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2088b1a948db41868615ae26cf83a06b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "77690b0c9f624f03bb554ea659482207"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/471M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b96b0dafc2e04ed1a6aec6e2a0e125e4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ff94d231d3e34549824e5a9fc6a6450f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.08M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05c6cc1bc95b490b97f7938ac710d84e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e94d29aa2a9f42b78174f7df8b60fa6f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7a51bef0c37a4963909ea4d345aa093e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:06:29.969734Z",
     "start_time": "2025-09-14T00:06:28.090721Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=\"ru_RU\", use_fast=False)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "    print(f\"Модель {MODEL_NAME} успешно загружена\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки модели {MODEL_NAME}: {e}\")\n",
    "    raise"
   ],
   "id": "11e5587e2e57e3f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель facebook/mbart-large-50-many-to-many-mmt успешно загружена\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:06:39.918482Z",
     "start_time": "2025-09-14T00:06:29.984967Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Подключение к Qdrant\n",
    "client = QdrantClient(host='localhost', port=6334)\n",
    "collection_name = \"rag_article_collection\"\n",
    "\n",
    "# Загрузка чанков из JSONL\n",
    "chunks = []\n",
    "with open('artifacts/rag_article.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))\n",
    "\n",
    "# Словарь для доступа к тексту по id\n",
    "chunk_dict = {chunk['id']: chunk['text'] for chunk in chunks}\n",
    "\n",
    "\n",
    "# Поиск релевантных чанков\n",
    "def search_chunks(query, top_k=3, min_score=0.4):\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "    search_result = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    ).points\n",
    "    matched_chunks = [\n",
    "        chunk_dict[hit.id] for hit in search_result\n",
    "        if hit.id in chunk_dict and hit.score >= min_score\n",
    "    ]\n",
    "    return matched_chunks\n",
    "\n",
    "\n",
    "# Генерация ответа\n",
    "def generate_response(query, chunks):\n",
    "    if not chunks:\n",
    "        return \"Не удалось найти релевантный контекст.\"\n",
    "    context = chunks[0]\n",
    "    tokenized_context = tokenizer(context, truncation=True, max_length=150, return_tensors=\"pt\")\n",
    "    truncated_context = tokenizer.decode(tokenized_context[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    prompt = f\"\"\"Ответь на русском языке кратко, используя контекст.\n",
    "\n",
    "Вопрос: {query}\n",
    "Контекст: {truncated_context}\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=False,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[\"ru_RU\"]\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    return response\n",
    "\n",
    "\n",
    "# Проверка коллекции\n",
    "collection_info = client.get_collection(collection_name=collection_name)\n",
    "if collection_info.points_count == 0 or collection_info.points_count != len(chunk_dict):\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# Логирование запроса и ответа\n",
    "def log_query(query, answer, chunks):\n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"relevant_chunks\": [chunk[:100] + \"...\" if chunk else \"Пусто\" for chunk in chunks]\n",
    "    }\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    log_file = 'logs/query_log.json'\n",
    "    try:\n",
    "        with open(log_file, 'r', encoding='utf-8') as f:\n",
    "            logs = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        logs = []\n",
    "    logs.append(log_entry)\n",
    "    with open(log_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(logs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Обновление журнала версий\n",
    "def update_version_log():\n",
    "    version_entry = {\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"files\": [\n",
    "            {\n",
    "                \"file\": \"rag_article.jsonl\",\n",
    "                \"description\": \"Исходный файл с чанками статей для RAG.\"\n",
    "            },\n",
    "            {\n",
    "                \"file\": \"embeddings.pkl\",\n",
    "                \"description\": \"Сохранённые эмбеддинги чанков для Qdrant.\"\n",
    "            },\n",
    "            {\n",
    "                \"file\": \"rag_result.json\",\n",
    "                \"description\": \"Результат последнего запроса (вопрос, ответ, релевантные чанки).\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    os.makedirs('artifacts', exist_ok=True)\n",
    "    with open('artifacts/version_log.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump([version_entry], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Запрос\n",
    "query = \"Что автор имеет в виду под 'иллюзией качества'?\"\n",
    "\n",
    "# Основной поиск и генерация\n",
    "relevant_chunks = search_chunks(query, top_k=3, min_score=0.4)\n",
    "answer = generate_response(query, relevant_chunks)\n",
    "\n",
    "# Сохранение результата\n",
    "result = {\"query\": query, \"answer\": answer, \"relevant_chunks\": relevant_chunks}\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "with open('artifacts/rag_result.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Логирование запроса\n",
    "log_query(query, answer, relevant_chunks)\n",
    "\n",
    "# Обновление журнала версий\n",
    "update_version_log()\n",
    "\n",
    "# Вывод\n",
    "print(f\"\\nВопрос: {query}\")\n",
    "print(f\"Ответ: {answer}\")\n",
    "print(\"Релевантные чанки:\")\n",
    "for i, chunk in enumerate(relevant_chunks, 1):\n",
    "    print(f\"Чанк {i}: {chunk[:100]}...\" if chunk else f\"Чанк {i}: Пусто\")"
   ],
   "id": "deca4b09975ae2e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Вопрос: Что автор имеет в виду под 'иллюзией качества'?\n",
      "Ответ: Внутри — ядро: логика, смысл, результат. Иллюзия Качества — это когда вы покупате шелуху, перепутав ее с сердцевиной. Вы смотрите на сайт, как на витрину — и верите, что это бизнес-инструмент. А на самом деле — просто декор.\n",
      "Релевантные чанки:\n",
      "Чанк 1: рассекаем “Качество” Иллюзия Качества — это когда вы платите за лоск, а получаете пустоту Качество ц...\n",
      "Чанк 2: анонимных перфекционистов Кстати, о “памятниках”. Какой самый вопиющий пример “Иллюзии качества” вы ...\n",
      "Чанк 3: 1: Поверхностное качество (Витрина) Что это? Всё, что можно оценить за 5 секунд, не вникая: пиксель-...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7435cbd788c6e4ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4495d129236a61ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
