{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:36:11.494018Z",
     "start_time": "2025-09-14T00:36:10.824609Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "\n",
    "# Загрузка текста статьи\n",
    "url = \"https://blog.dzencode.com/ru/illyuziya-kachestva-vash-sayt-idealen-pozdravlyaem-vy-tolko-chto-sozhgli-byudzhet/\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "article_text = soup.get_text(separator='\\n')\n",
    "\n",
    "# Сохранение текста\n",
    "with open('artifacts/article.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(article_text)\n",
    "\n",
    "# Метаданные\n",
    "metadata = {\n",
    "    \"url\": url,\n",
    "    \"language\": \"ru\",\n",
    "    \"date\": \"unknown\",  # Дата не указана, можно уточнить позже\n",
    "    \"topic\": \"Иллюзия качества в веб-дизайне\",\n",
    "    \"project\": \"RAG_Pipeline_Test\",\n",
    "    \"lang\": \"ru\"\n",
    "}\n",
    "with open('artifacts/metadata.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(metadata, f, ensure_ascii=False, indent=2)"
   ],
   "id": "cd7aaf2855bf1a94",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:36:11.523636Z",
     "start_time": "2025-09-14T00:36:11.509757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "# Чтение исходного текста\n",
    "with open('artifacts/article.txt', 'r', encoding='utf-8') as f:\n",
    "    article_text = f.read()\n",
    "\n",
    "# Предобработка: удаление HTML-тегов и лишних символов\n",
    "cleaned_text = re.sub(r'<.*?>', '', article_text)  # Удаление HTML-тегов\n",
    "cleaned_text = re.sub(r'\\s+', ' ', cleaned_text)  # Замена множества пробелов на один\n",
    "cleaned_lines = cleaned_text.splitlines()  # Разбиение по любым разрывам строк\n",
    "cleaned_text = '\\n'.join(line.strip() for line in cleaned_lines if line.strip())  # Фильтр пустых строк\n",
    "\n",
    "# Сохранение чистого текста\n",
    "with open('artifacts/cleaned_article.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(cleaned_text)"
   ],
   "id": "eb45dfd05873e40d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:36:12.875353Z",
     "start_time": "2025-09-14T00:36:11.692380Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Чтение очищенного текста\n",
    "with open('artifacts/cleaned_article.txt', 'r', encoding='utf-8') as f:\n",
    "    cleaned_text = f.read()\n",
    "\n",
    "# Разбиение на чанки\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=512,\n",
    "    chunk_overlap=50,\n",
    "    length_function=len\n",
    ")\n",
    "chunks = text_splitter.split_text(cleaned_text)\n",
    "\n",
    "# Подготовка данных для JSONL с ID и метаданными\n",
    "data = []\n",
    "for i, chunk in enumerate(chunks):\n",
    "    entry = {\n",
    "        \"id\": i,\n",
    "        \"text\": chunk,\n",
    "        \"metadata\": {\n",
    "            \"url\": \"https://blog.dzencode.com/ru/illyuziya-kachestva-vash-sayt-idealen-pozdravlyaem-vy-tolko-chto-sozhgli-byudzhet/\",\n",
    "            \"language\": \"ru\",\n",
    "            \"date\": \"unknown\",\n",
    "            \"topic\": \"Иллюзия качества в веб-дизайне\",\n",
    "            \"project\": \"RAG_Pipeline_Test\"\n",
    "        }\n",
    "    }\n",
    "    data.append(entry)\n",
    "\n",
    "# Сохранение в JSONL\n",
    "with open('artifacts/rag_article.jsonl', 'w', encoding='utf-8') as f:\n",
    "    for entry in data:\n",
    "        f.write(json.dumps(entry, ensure_ascii=False) + '\\n')"
   ],
   "id": "bb5f229f475b136c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:36:23.221818Z",
     "start_time": "2025-09-14T00:36:12.882517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance, PointStruct\n",
    "import json\n",
    "import pickle\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Чтение чанков из JSONL\n",
    "chunks = []\n",
    "try:\n",
    "    with open('artifacts/rag_article.jsonl', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            chunks.append(json.loads(line))\n",
    "except FileNotFoundError:\n",
    "    print(\"Ошибка: Файл 'artifacts/rag_article.jsonl' не найден.\")\n",
    "    raise\n",
    "\n",
    "# Генерация эмбеддингов\n",
    "texts = [chunk['text'] if chunk['text'] else \" \" for chunk in chunks]\n",
    "vectors = embeddings.embed_documents(texts)\n",
    "\n",
    "# Подключение к Qdrant\n",
    "try:\n",
    "    client = QdrantClient(host='localhost', port=6333)\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка подключения к Qdrant: {e}\")\n",
    "    raise\n",
    "\n",
    "# Очистка и создание коллекции\n",
    "collection_name = \"rag_article_collection\"\n",
    "if client.collection_exists(collection_name):\n",
    "    client.delete_collection(collection_name)\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(\n",
    "        size=len(vectors[0]),\n",
    "        distance=Distance.COSINE\n",
    "    )\n",
    ")\n",
    "\n",
    "# Загрузка данных в Qdrant\n",
    "points = [\n",
    "    PointStruct(\n",
    "        id=chunk['id'],\n",
    "        vector=vector,\n",
    "        payload=chunk['metadata']\n",
    "    )\n",
    "    for chunk, vector in zip(chunks, vectors)\n",
    "]\n",
    "client.upsert(collection_name=collection_name, points=points)\n",
    "\n",
    "# Сохранение эмбеддингов\n",
    "with open('artifacts/embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(vectors, f)"
   ],
   "id": "f96ac98ac3ebe6ea",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\balnc3r\\AppData\\Local\\Temp\\ipykernel_16204\\3254091620.py:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:36:25.015338Z",
     "start_time": "2025-09-14T00:36:23.237881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "MODEL_NAME = \"facebook/mbart-large-50-many-to-many-mmt\"\n",
    "try:\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=\"ru_RU\", use_fast=False)\n",
    "    model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_NAME)\n",
    "    print(f\"Модель {MODEL_NAME} успешно загружена\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка загрузки модели {MODEL_NAME}: {e}\")\n",
    "    raise"
   ],
   "id": "11e5587e2e57e3f5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель facebook/mbart-large-50-many-to-many-mmt успешно загружена\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-14T00:36:36.414815Z",
     "start_time": "2025-09-14T00:36:25.030081Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "import mlflow  # Новый импорт для MLflow\n",
    "\n",
    "# Инициализация эмбеддингов\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
    "\n",
    "# Подключение к Qdrant\n",
    "client = QdrantClient(host='localhost', port=6333)\n",
    "collection_name = \"rag_article_collection\"\n",
    "\n",
    "# Загрузка чанков из JSONL\n",
    "chunks = []\n",
    "with open('artifacts/rag_article.jsonl', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        chunks.append(json.loads(line))\n",
    "\n",
    "# Словарь для доступа к тексту по id\n",
    "chunk_dict = {chunk['id']: chunk['text'] for chunk in chunks}\n",
    "\n",
    "\n",
    "# Поиск релевантных чанков\n",
    "def search_chunks(query, top_k=3, min_score=0.4):\n",
    "    query_vector = embeddings.embed_query(query)\n",
    "    search_result = client.query_points(\n",
    "        collection_name=collection_name,\n",
    "        query=query_vector,\n",
    "        limit=top_k,\n",
    "        with_payload=True,\n",
    "        with_vectors=False\n",
    "    ).points\n",
    "    matched_chunks = [\n",
    "        chunk_dict[hit.id] for hit in search_result\n",
    "        if hit.id in chunk_dict and hit.score >= min_score\n",
    "    ]\n",
    "    return matched_chunks\n",
    "\n",
    "\n",
    "# Генерация ответа\n",
    "def generate_response(query, chunks):\n",
    "    if not chunks:\n",
    "        return \"Не удалось найти релевантный контекст.\"\n",
    "    context = chunks[0]\n",
    "    tokenized_context = tokenizer(context, truncation=True, max_length=150, return_tensors=\"pt\")\n",
    "    truncated_context = tokenizer.decode(tokenized_context[\"input_ids\"][0], skip_special_tokens=True)\n",
    "    prompt = f\"\"\"Ответь на русском языке кратко, используя контекст.\n",
    "\n",
    "Вопрос: {query}\n",
    "Контекст: {truncated_context}\"\"\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True)\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=150,\n",
    "        num_return_sequences=1,\n",
    "        do_sample=False,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[\"ru_RU\"]\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()\n",
    "    return response\n",
    "\n",
    "\n",
    "# Проверка коллекции\n",
    "collection_info = client.get_collection(collection_name=collection_name)\n",
    "if collection_info.points_count == 0 or collection_info.points_count != len(chunk_dict):\n",
    "    raise SystemExit\n",
    "\n",
    "\n",
    "# Логирование запроса и ответа\n",
    "def log_query(query, answer, chunks):\n",
    "    log_entry = {\n",
    "        \"timestamp\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"query\": query,\n",
    "        \"answer\": answer,\n",
    "        \"relevant_chunks\": [chunk[:100] + \"...\" if chunk else \"Пусто\" for chunk in chunks]\n",
    "    }\n",
    "    os.makedirs('logs', exist_ok=True)\n",
    "    log_file = 'logs/query_log.json'\n",
    "    try:\n",
    "        with open(log_file, 'r', encoding='utf-8') as f:\n",
    "            logs = json.load(f)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        logs = []\n",
    "    logs.append(log_entry)\n",
    "    with open(log_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(logs, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Обновление журнала версий\n",
    "def update_version_log():\n",
    "    version_entry = {\n",
    "        \"version\": \"1.0.0\",\n",
    "        \"date\": datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
    "        \"files\": [\n",
    "            {\n",
    "                \"file\": \"rag_article.jsonl\",\n",
    "                \"description\": \"Исходный файл с чанками статей для RAG.\"\n",
    "            },\n",
    "            {\n",
    "                \"file\": \"embeddings.pkl\",\n",
    "                \"description\": \"Сохранённые эмбеддинги чанков для Qdrant.\"\n",
    "            },\n",
    "            {\n",
    "                \"file\": \"rag_result.json\",\n",
    "                \"description\": \"Результат последнего запроса (вопрос, ответ, релевантные чанки).\"\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    os.makedirs('artifacts', exist_ok=True)\n",
    "    with open('artifacts/version_log.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump([version_entry], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "\n",
    "# Запрос\n",
    "query = \"Что автор имеет в виду под 'иллюзией качества'?\"\n",
    "\n",
    "# Основной поиск и генерация с MLflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5001\")  # Настройка MLflow\n",
    "with mlflow.start_run():  # Начать MLflow run\n",
    "    mlflow.log_param(\"query\", query)  # Логирование запроса\n",
    "    relevant_chunks = search_chunks(query, top_k=3, min_score=0.4)\n",
    "    answer = generate_response(query, relevant_chunks)\n",
    "    mlflow.log_param(\"num_chunks\", len(relevant_chunks))  # Логирование числа чанков\n",
    "    mlflow.log_artifact(\"artifacts/rag_result.json\")  # Логирование артефакта\n",
    "\n",
    "# Сохранение результата\n",
    "result = {\"query\": query, \"answer\": answer, \"relevant_chunks\": relevant_chunks}\n",
    "os.makedirs('artifacts', exist_ok=True)\n",
    "with open('artifacts/rag_result.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(result, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Логирование запроса\n",
    "log_query(query, answer, relevant_chunks)\n",
    "\n",
    "# Обновление журнала версий\n",
    "update_version_log()\n",
    "\n",
    "# Вывод\n",
    "print(f\"\\nВопрос: {query}\")\n",
    "print(f\"Ответ: {answer}\")\n",
    "print(\"Релевантные чанки:\")\n",
    "for i, chunk in enumerate(relevant_chunks, 1):\n",
    "    print(f\"Чанк {i}: {chunk[:100]}...\" if chunk else f\"Чанк {i}: Пусто\")"
   ],
   "id": "deca4b09975ae2e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run bright-wolf-353 at: http://localhost:5001/#/experiments/0/runs/29326a205e5a40aa9954dc43e453aa2b\n",
      "🧪 View experiment at: http://localhost:5001/#/experiments/0\n",
      "\n",
      "Вопрос: Что автор имеет в виду под 'иллюзией качества'?\n",
      "Ответ: Внутри — ядро: логика, смысл, результат. Иллюзия Качества — это когда вы покупате шелуху, перепутав ее с сердцевиной. Вы смотрите на сайт, как на витрину — и верите, что это бизнес-инструмент. А на самом деле — просто декор.\n",
      "Релевантные чанки:\n",
      "Чанк 1: рассекаем “Качество” Иллюзия Качества — это когда вы платите за лоск, а получаете пустоту Качество ц...\n",
      "Чанк 2: анонимных перфекционистов Кстати, о “памятниках”. Какой самый вопиющий пример “Иллюзии качества” вы ...\n",
      "Чанк 3: 1: Поверхностное качество (Витрина) Что это? Всё, что можно оценить за 5 секунд, не вникая: пиксель-...\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "7435cbd788c6e4ac"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "4495d129236a61ae"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
